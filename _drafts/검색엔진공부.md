---
layout: post
categories: articles
title:  "title"
excerpt: "excerpt"
tags: []
date: 2015-05-27 15:27:43
modified: 2015-05-27 15:27:43
image: 
  feature: filename
  credit: image owner
  creditlink: original link
share: true
sitemap: false
---

1. 가상함수
http://blog.naver.com/loveall0926/20206819754

2. STL 라이브러리
http://blog.naver.com/vgb910526/220290944618
STL 공식 서포트 페이지를 좀 더 추천

3. 함수 템플릿
http://blog.naver.com/bungkun1349/220298408563

4. iterator 패턴
 - 요지는 iterator 를 별도로 사용함으로써 루프 방법과 자료구조를 분리시키는 것 -> 자료구조가 바뀌어도 루프 코드를 검드릴 필요 없게.
http://blog.naver.com/hwangsuyun/220329662289
http://poohwaa.tistory.com/35
http://cafe.naver.com/cafec/994

5. 파일 입출력
http://blog.naver.com/remocon33/220211735504

6. Makefile 작성, make 명령어
- 그냥 그때그때 gcc 컴파일하는 것은 학생 때나 하던 짓이다
- Makefile 작성하고 적극적으로 make 사용하여 번거로움을 피하고 컴파일 절차 시간을 단축해 생산성을 높여라
- vi와 연동하여 편집 중에 컴파일 및 디버그해라
- http://www.cs.colby.edu/maxwell/courses/tutorials/maketutor/
- https://www.cs.umd.edu/class/fall2002/cmsc214/Tutorial/makefile.html
- http://mrbook.org/blog/tutorials/make/
- autoconf 설명: http://oopsoopskeke.tistory.com/70
 => make가 컴파일을 손쉽게 해주었으나 프로그램 이식성을 보장하지는 못해 (32bit vs. 64bit 시스템, OS 차이 등)
 => 프로그래밍 과정에서 프로그램이 사용될 시스템 사항을 결정할 수는 없다
 => "컴파일 과정에서 고려해 이식성 있게 빌딩하게 해주면 어떨까?" -> autoconf, automake로 Makefile을 시스템에 맞게 자동 생성하자.
 => 이 파트는 make 하기 전 다른 배포 프로그램들이 흔히 갖고 있는 ./configure 가 무엇이었는가에 대한 답을 준다
 => autoscan 흐름: autoscan -> configure.ac -> aclocal(->aclocal.m4), autoheader(->config.h.in)-> autoconf -> configure
 => ed 흐름: ed -> Makefile.am -> automake -> Makefile.in -> configure
- 예시코드:
# 일반적으로 많이 사용하는 변수 관용어
CC=gcc # 컴파일러명
CFLAG=-c # 컴파일 옵션. cpp의 경우 CPPFLAG 하는 경우도 있다

# 사용자가 만든 변수
EXE_NAME=-o # 실행파일 이름 지정 옵션. 여기에 실행파일명까지 다 적으려다가 그냥 옵션만 했다
NEXUS_HEADER_DIR=-I/naver/search-env/package/nexus-2.8.4-arch-x86_64/include # -I: 헤더파일 경로
SC2_LIBRARY_DIR=-L/naver/search-env/package/nexus-2.8.4-arch-x86_64/lib # -L: 라이브러리 경로
SC2_LIBRARY=-lsc2 # -l: 라이브러리 이름 -> 이러면 이제 라이브러리 경로에 있는 실제 파일명은 규칙상 libsc2.a(정적) 혹은 libsc2.so(동적) 가 된다.

# 특별한 옵션 없이 make만 사용할 경우 가장 위의 role부터 우선 실행된다
# make all 명령을 위해 만드는 role. 관용적으로 사용
all: sc2

# make install. 여기는 빌드가 완료된 실행파일을 특정 폴더에 카피해서 설치하는 로직이 들어간다. 관용적으로 사용. 본 예제는 아무 일도 안 함
install: all

# 빌드 명령부는 이런 식으로.
sc2: sc2.o
        $(CC) sc2.o $(SC2_LIBRARY_DIR) $(SC2_LIBRARY) $(EXE_NAME) sc2

# 단일 o 파일 컴파일 코드 예제
# sc2.o: sc2.cpp
#       $(CC) $(CFLAG) $(NEXUS_HEADER_DIR) sc2.cpp

# 보통은 한 프로젝트 폴더의 여러 소스를 일괄 컴파일하는 경우가 많으므로 이런 확장자 role을 사용한다
# * 내부 매크로 -> $@: 목표파일, $<: 입력파일, $*: 확장자가 없는 현재의 입력파일.
.cpp.o:
        $(CC) $(CFLAG) $(NEXUS_HEADER_DIR) $< # $<: 입력 파일 전체. 빌드 명령부에 있는 파일들이 입력 파일 대상 (본 예제는 sc2.o 하나)

# make clean. 컴파일, 빌드 결과물을 다 지울 때 사용. 역시 관용어에 속함
clean:
        rm -f *o sc2

7. vim 과 make 연동
 - vim 콘솔(:)에서는 !명령어로 shell 명령어 입력 후 결과 보기 가능 (ex: !ls, !mkdir 등..)
 - 그러나 make만 예외적으로 ! 없이 그냥 사용 가능
 - 즉 Makefile 을 작성해두면 vim에서 나오지 않고 바로 저장(w) 후 컴파일 가능
 - make 컴파일 후 에러가 발생하면 첫번째 에러가 발생한 라인으로 이동해줌

8. copen, cp, cn
 - vim 연동 c언어 에러 찾기 명령어
 - 콘솔(:)에서 입력
 - cp=이전에러, cn=다음에러

9. 블록 스코프
 - 아무것도 없이 {} 로 둘러진 코드
 - C언어 feature
 - 변수는 2종류: static, auto(생략 가능)
 - auto, 지역변수를 블록 스코프안으로 넣어 생명주기를 제어할 수 있다
 - 같은 역할을 하는 변수를 반복적으로 다른 초기화나 목적에 사용하거나, 루프문의 이터레이터를 이것으로 처리하면 좋다

10. main() 파라미터 사용하기
 - argc: 파라미터 입력받은 수
 - argv[]: 각 파라미터. 0번은 프로그램 이름. 파라미터는 1번부터.
 - http://blog.naver.com/darkred11/50170577076

11. 정적 라이브러리, 동적 라이브러리
 - 라이브러리 링킹 vs 헤더 인클루딩 : 소스가 바이너리 컴파일 되어있느냐 아니냐
 - 정적라이브러리: archive 파일로도 부름. '*.a'. 여러 오브젝트를 묶어 하나 파일로 사용 가능. 컴파일 시간에 코드를 포함.
  => 우선 전체 .c 소스들은 오브젝트 코드로 컴파일해야 함. ex: gcc -c main.c project.c
  => 정적라이브러리를 만드는 명령어: ar, 라이브러리 파일명 규칙: lib + 이름 + .a
    ex: ar cr libproject.a project.o
  => 컴파일은 다음과 같은 방법들이 존재
    ex: gcc main.c -L/source/path/ -lproject (-L, -l 옵션과 파라미터를 붙여 쓰는것이 난감한 부분이다)
    ex: gcc main.c libproject.a (이것도 기본적으로 같게 동작)
    ex: gcc main.c project.o (원리나 의미상 이것도 거의 같다)
  => 결국 정적라이브러리는 *.o 파일의 집합을 하나의 .a 파일로 패키징 한 형태에 불과
 - 동적라이브러리: 런타임(실행) 시간에 코드를 포함시키는 바이너리 코드 파일. 본체 소스가 변경되어도 새로 컴파일할 필요 없다. 자유로운 교체가 가능
  => 사실 -o 옵션으로 이름 지정하지 않으면 a.out 으로 출력되는, 실행가능한 바이너리 파일이다. 물론 프로그램의 일부일 뿐이니 에러가 나겠지만.
  => gcc 옵션
    i) -shared: *.o 파일을 모아 dso(동적라이브러리) 패키지를 만들 때 들어가는 옵션. (2글자 이상의 롱 파라미터인데 -- 가 아니라 -인 점도 불규칙적)
    ii) -fPIC: Position-Independent_Code. 이는 dso가 main 프로그램과 메모리 위치로부터 독립적임을 의미한다. dso를 만들 때 써야 하는 옵션.
      ex: gcc -c -fPIC project.c (dso가 될 소스코드를 -fPIC 옵션으로 컴파일)
          gcc -shared -fPIC -o libproject.so project.o (동적라이브러리 생성)
          gcc -shared -fPIC -Wl,-soname,libproject.so.1 -o libproject.so.1.0 project.o (soname 지정하는 경우. -Wl은 링커에 파라미터를 직접 넘겨준다는 뜻. , 뒤에 한칸 띄면 안되는 것이 특징. soname은 버젼관리에 중요하고, 일단 따라하고 자세한건 더 찾아봐라)
          gcc main.o -L/source/path/ -lproject
          빌드로 끝이 아니고 버젼 단계별로 심볼릭 링크를 만들어줘서 관리한다.
          project.so -> project.so.1 -> project.so.1.0 ->  project.so.1.0.0
  => 
 - 정적 + 동적
  => 두 파일이 한 곳에 있을 경우 우선 순위는 동적 라이브러리
  => 정적 라이브러리로 컴파일 하고자 할 경우 옵션: -static
 - http://blueamor.tistory.com/707
 - http://www.yolinux.com/TUTORIALS/LibraryArchives-StaticAndDynamic.html

12. 함수 포인터 (function pointer)
 - c/c++
 - 선언: int (*func)(int a, int b);
 - 사용: func = func1; (func1은 int func1(int a, int b) {} 로 구현되어있음)
         printf("%d", func(a, b));
 - c에서도 함수 이름만으로 함수 주소값을 넘기는게 가능하다!
 - 주의: 같은 반환 타입, 같은 수의 같은 타입 인자로 일치시켜야 함
 - 용도: 같은 이름의 함수 포인터로 같은 개념 속에서 약간씩 다른 동작을 하는 여러 함수를 참조하여, 로직 코드를 크게 손대지 않고 기능을 갈아끼울 수 있다.
 - http://blog.naver.com/vgb910526/220311820912
 - http://yhjeong89.blog.me/220226186244


13. bashrc vs. bash_profile
 - bash_profile은 login shell이 실행 될 떄, bash_profile은 interactive non-login shell의 실행을 위한 것
 - login_shell: bash를 처음 킬 때, 콘솔에 로그인하거나, ssh를 통해 로그인하는 경우, the initial command prompt 실행되기 전
 - interactive non-login shell: 로그인 후에 새로운 터미널 창을 열거나 window command prompt가 실행되기 전
 - 구분하는 이유: bash_profile은 load average, current users와 같이 로그인과 관련된 정보들을 얻을 때 필요하고 bashrc는 새로운 터미널을 열 때마다 정보를 받고 싶을 때 필요
 - 로그인 할 때는 지원을 안해준다면 경우에 따라서 bashrc에 있는 내용이 실행이 안되기도 하므로, bash_profile에서 bashrc의 내용들을 불러오도록 하도록 하는게 좋은 방법
 - ex: (bash_profile 안에서) [[ -r ~/.bashrc ]] && . ~/.bashrc
 - 번외, zshrc: bash와 같은 shell의 한 종류, zshrc는 login이든 non-login이든 상관없이 항상 실행되므로 zshrc를 bashrc와 bash_profile처럼 구별해서 쓸 필요는 없으나, login에서만 동작하는 zprofile이 존재는 함
 - http://vnthf.github.io/blog/bash/
 
14. 리눅스(linux) 새로 배운 명령어
 - curl: url로 request 날리고 응답을 text로 출력한다.
  - -H: 헤더 추가 (ex: curl http://naver.com -H "Content-Type:text/html")
   => http://stackoverflow.com/questions/1745318/curl-setting-content-type-incorrectly
  - -d: 데이터 추가. POST method가 됨. 문자열을 넣을 수도 있고 파일 넣을 수도 있음. 파일은 앞에 @ 추가 (ex: curl http://naver.com -d @text.txt)
  - -XPOST, -XDELETE, -XGET, -XPUT ... : http method 변경
 - 운영체제 정보 확인
  - 리눅스 종류 확인: 파일. /etc/*-release
  - 커널 버전 확인: uname -r, uname -a(전체 정보), cat /proc/version
  - 호스트명 확인: hostname (-i: ip 확인), echo $HOSTNAME, env | grep HOSTNAME, set | grep HOSTNAME, cat /proc/sys/kernel/hostname
 - cut: 읽은 파일에서 선택한 줄들만 표준 추력으로 표시
  => ex) cut -d '\t' -f 2 -> 구분자 탭으로 2컬럼만 표시
 - mail: 시스템 기본 메일
  => mail -N: 메일을 읽거나 메일 폴더를 편집할 때 초기 메시지 헤더가 안 나오게 한다
  => mail 커맨드 프롬프트 명령어
    d *: 다 지운다
  => /var/mail/username: username 이름으로 메일 기록이 다 남아있다. 이를 그냥 지우면 간단하게 메일을 다 날릴 수 있다. su 권한 필요.
  => http://stackoverflow.com/questions/7076186/how-do-i-purge-a-linux-mail-box-with-huge-number-of-emails
 - date: 날짜 출력 명령어
  => ex: date +%y%m%d-%H%M%S -> 2자리로 년월일-시분초
 - xargs: stdin으로 커맨드를 빌드하거나 실행시키는 명령어. rm은 인자값을 직접 줘야지 stdin을 받아 처리하진 못한다. 이것으로 가능
  => 이 방법의 장점은 다른 명령의 출력을 그대로 인자로 쓸 수 있다는 점, 인자가 길어도 사용할 수 있다는 점
  => ex: find . | grep '.py$' | xargs rm
  => ex: find . | grep -Z '.py$' | xargs -0 rm -> GNU grep 사용할 땐 이렇게 해야 할 수도 있다
  => https://en.wikipedia.org/wiki/Xargs
  => http://unix.stackexchange.com/questions/9597/giving-grep-output-to-rm
 - uname: print system info.
  => -a: all
  => -r: kernel release
 - hostname: 호스트네임을 보여준다. 서버의 이름
  => -i: IP 주소
 - file: 파일의 인코딩 정보, 바이너리인지 플레인 텍스트인지 등의 속성 정보 출력 (ex: file sc2.cpp)
 - nm: 오브젝트(*.o, 혹은 실행파일)의 심볼 상태를 체크하여 알려준다. 잘 작동하지 않을 때 dso 등에 사용하면 어느 객체가 구현되지 않았거나 이상이 있는지 확인할 때 좋다. (ex: nm sc2.so)
 - coll-conf 도 적절히 해주어야 한다
 - scp vs. rsync : 둘 다 원격 리눅스 시스템간 파일 복사 유틸리티인데, 유효한 차이점은 scp의 경우 심볼릭 링크를 복사하지 못하고 모두 파일 카피한다는 점 정도이다.
  => rsync의 경우 /etc/rsyncd.conf 에 환경설정 파일이 저장되어 있는데, 접근 권한 관련 문제가 생길 경우 hosts allow 값으로 접근 허용을 원하는 ip가 들어있는지 확인해야 할 필요가 있다. 구분자는 comma. (ex: hosts allow=192.168.0.0/24, 10.24.57.141, 10.24.56.253)
  => rsync 사용법 참고 사이트: http://www.joinc.co.kr/modules/moniwiki/wiki.php/Site/Tip/Rsync
  => 14. 06. 24. 팀장님: scp는 ssh 프로토콜 원격 카피 툴이고, rsync는 rsync 프로토콜을 사용한다는 것이 가장 주요한 차이점이다.
  => rcp 도 있다. rlogin 프로토콜을 사용하여 파일 카피를 시도한다.
 - ulimit: 제한기능을 지원하는 시스템에서 쉘, 쉘이 실행한 프로세스에 대하여 사용 자원을 제한할 수 있도록 해주는 명령어.
  => core file 사이즈를 확인할 수 있고, 제어도 가능하다. 보통 0으로 되어 있어 바이너리 실행의 메모리 결과를 덤프하지 않는다. core 덤프를 위해 이 값을 조절하는 경우나, 조절하는 프로그램도 있다.
  => ulimit -a: 전체 항목 보기
 - gdb: 메모리 에러(ex: segmentation fault)가 생겼을 때 linux는 당시 상황을 메모리 덤프하여 기록할 수 있는데 이를 coredump 라 하고 그 파일을 core, 혹은 core.{pid} 로 표시한다. 쓰레기 같지만 에러 추적을 위해 필요한데, gdb는 이 파일을 해석해주는 프로그램으로, 사실 자바의 스택 트레이스와 같은 기능을 수행하며, 사용법을 깊이 이해하면 core 파일 외에도 다른 방향으로 에러 트레이싱에 응용될 수 있다.
  => gdb binary-file core-file (ex: gdb /example/apache/bin/httpd ./core.1474)
 - libtool: 리눅스 시스템에 동적 라이브러리를 만들어 설치한다면 그냥 할 수도 있지만, 그 절차에 특화된 컴파일 명령어
  => http://www.gnu.org/software/libtool/manual/html_node/Installing-libraries.html
 - chkconfig: 리눅스서버가 부팅될 때 실행될 프로그램을 설정하는 역활을 하는 유틸리티
  => 런레벨: 0~6단계까지, 부팅의 단계가 존재 (centOS, redhat, fedora 동일) -> 종료, 단일 사용자, X, 다중, X, 다중 GUI, 재부팅
  => http://blog.naver.com/diceworld/220295874000
 - df: 파일시스템 디스크 공간, 사용량, 잔여량 표시
  => 많이 쓰는 옵션: df -h
 - du: 파일 사용량 계산 (본 폴더만, 하위 포함, 폴더만 표시, 파일까지 다 표시 등을 조절 가능)
  => -h: 보기좋게
  => -s: 여기만
  => -a: 개별 파일까지 다 표시
 - split: 파일을 나눠준다
  => ex: split -a 5 -d -l 500 source dest_folder/output
  => -a: 나눈 파일의 뒤 규칙명(suffix)의 개수를 정한다, -d: suffix를 숫자로 한다, -l: 나눌 기준을 라인 수로 지정한다.
 - bc: 수식 계산 명령어. 셸 스크립트는 정수 계산의 한계를 갖지만 이건 실수 연산도 가능
  => ex: echo "3.25+231.76" | bc
 - read: 입력을 변수에 저장한다. "계속하시겠습니까(y/n)" 응용 가능
  => read [파라미터] [변수]
  => -e: "readline" 프로그램을 써서 라인 입력을 받는다. => 그런데 그게 무슨 차이인지 잘 모르겠음.
  => -p: read 명령으로 읽기 전에 문자열을 출력한다.
  => ex: read -e -p "Enter your choice: " VAR_CHOICE
  => 변수명을 지정하지 않으면 기본 내장 변수로 $REPLY를 사용한다.
  => http://www.linuxnix.com/2012/05/7-linux-read-command-examples-shell-scripting.html
 - time: 스크립트나 프로그램 실행 시간을 재준다. 직접 시간 재는 코딩하는 것보다 편리함
  => 직접 잰다면 아마 `date +%s%3N` 같은 식으로 start end 찍어서 빼서 출력했을 것이다 (http://stackoverflow.com/questions/16548528/linux-command-to-get-time-in-milliseconds)
  => time ex: time sample.sh
  => times 명령어도 있으나 동작은 약간 다르고 아직 정확히 파악하진 않았다.
  => http://unix.stackexchange.com/questions/52313/how-to-get-execution-time-of-a-script-effectively
  => time 출력(리디렉션)은 stderr이므로 별도 저장을 원한다면: ex) (time ls -al) > result 2> time_result
  => 한번에 저장을 원한다면: ex) (time ls -al) &> result_whole
  => http://stackoverflow.com/questions/2408981/how-can-i-redirect-the-output-of-the-time-command
  => time이 걸린 녀석의 백그라운드 실행은 약간 특이하게 동작한다.
    ex) time ls -al & > result -> 출력 다 되어버리고 입력 대기 받음. result는 빈 파일
    ex) (time ls -al &) > result -> time 결과만 출력되어버리고 입력 대기 받음. result는 ls -al 결과물
    ex) (time ls -al &) &> result -> time 결과만 출력되어버리고 대기 없음. result는 ls -al + time result.
 - grep 의 마법
  => -v: 반대로 검색. 검색어가 없는 줄 출력
  => -n: 라인 번호 추가
  => -c: 검색어 검색 횟수 카운트
  => --color: 찾은 글씨 색칠
  => -w: 검색어가 전체 단어를 이루고 있을 경우만 검색 (ex: 그냥 grep aa file 하면 => "sample text aaa yeah" 에서 aaa 속의 aa를 검색한다)
  => -A num: 검색 라인 이후 num 라인 만큼 출력
  => -B num: 검색 라인 이전 num 라인 만큼 출력
  => -C num: 검색 라인 이전 이후 num 라인 만큼 출력
  => 여러개 검색어 검색: grep 'word1\|word2\|word3' /location/file (egrep 은 'word1|word2|word3' 라고만 해도 된다) (원래 -E 옵션 필요, POSIX에서는 이 옵션 없이도 해준다)
  => 좋은 예시: 로그 파일에서 특정 단어만을 검색해보자 (egrep -wi --color 'warning|error|critical' /var/log/messages)
  => 특정 단어의 컬러링(하일라이팅)만 하기: 모든 글씨와 찾고 싶은 패턴을 regex로 동시에 잡으면 된다.
    ==> grep --color -E '^|pattern'
    ==> '^' 는 모든 라인의 시작점을 잡아내지만 글씨가 아니므로 highlight 되지 않는다. pattern만 결과적으로 칠해짐
    ==> http://stackoverflow.com/questions/7393906/highlight-text-similar-to-grep-but-dont-filter-out-text
 - basename, dirname, readlink
  => basename: 파일명만 추출. 확장자도 지정하여 뗄 수 있다. (ex: basename /etc/test.py .py ==> "test")
  => dirname: 디렉토리 경로만 추출
  => radlink: 심볼릭 링크 내용을 읽어준다
 - ln vs. link
  => ln 은 -s 옵션으로 symbolic link를 만드는 것이 가능하지만, link는 하드 링크 전용이다. 따라서 폴더 링크도 생성할 수 없다.
 - gzip
  => 읽는 법: 지집 (https://youtu.be/Mjab_aZsdxw)
  => 그냥 쓰면 압축, -d 옵션으로 압축 해제
  => 압축하든 해제하든 원본이 유지되지 않고 바뀌는 식으로 동작하는게 기본
  => -c: 아웃풋을 파일이 아니라 stdout으로 돌린다. 원본이 바뀌지 않는다.
 - uniq
  => stdout이나 파일을 받아 중복 라인을 제거한다. 때문에 먼저 정렬이 선행되어야 한다
  => ex: 1 1 2 3 4 4 4 5 6 (구분자는 newline) -> 1 2 3 4 5 6
  => -c: 앞에 반복 수를 표시해준다.
 - 백그라운드(멀티, 병렬) 잡(데몬) 컨트롤
  => ./program &: 프로그램을 데몬으로 실행
  => fg: 방금 실행한 백그라운드 잡으로 돌아간다
  => bg: 백그라운드 잡을 보여준다
  => jobs: 백그라운드 잡을 보여주는데 표시 방법이 bg랑 조금 다르다. 중요한 차이는 아직 모름
  => kill %1: 1번 job을 죽인다
  => http://linuxcommand.org/lts0080.php
 - tee: stdout, file 동시 출력
  => ex) echo "test" | tee test.txt
  => 그런데 배치 작업을 시켜보니 응답속도가 느리다. 화면 멈춘 줄. 스택 오버플로우에는 내부 복사 구조 상 느린 점이 있다는 의견이 있다
 - seq: 연속된 숫자를 찍어준다.
  => 기본: seq 처음숫자 증가크기 최종숫자 (ex: seq 1 2 30 -> 1~30까지 2칸씩.)
  => 처음숫자 생략하면 1부터, 증가크기 생략하면 1씩, 증가크기는 소수점 가능. 최종 숫자는 생략 불가.
  => -f: 포맷 정하기. (ex: -f %03g -> 3자리 출력, 공백은 0으로 메꿈)
  => -w: 끝 수자 크기만큼 공백을 0으로 출력. (ex: -w 10 -> 01 02 03 04 05 06 07 08 09 10)
  => ex) seq -f "%02g" 1 31 -> 1~31 까지 0을 찍으면서 2자리로 출력
  => seq는 for문과 조합 가능 (ex: for i in `seq 10`; do something; done)
 - netstat: 네트워크 상태 확인. 
  => netstat -nap (열려있는 모든 포트 스캔)
 - lsof: 시스템에서 동작하고 있는 모든 프로세스에 의해서 열려진 파일들에 관한 정보를 보여주는 시스템 관리 명령어
  => lsof -i(어쩌면 I): 열려있는 인터넷 소켓 확인
 - tr: 특정 문자를 처리한다. 파이프로 입력 받기 지원. sed와 유사한 동작이지만 문자열을 지원하지 않는 것이 차이.
  => 파라미터 없는 기본동작은 그 문자를 다른 문자로 치환한다.
  => -d: 그 단어를 지운다.
  => 범위 표현을 지원한다. (ex: a-z, A-Z, [:lower:], [:upper:])
  => ex) tr -d ' ' < test.txt -> 입력된 문자열에서 스페이스바를 싹 지워서 다시 출력한다
  => ex) echo "this is test" | tr " " "\n" -> 스페이스를 엔터로 치환
  => http://greenfishblog.tistory.com/66
 - trap: 셸 시그널을 받아 명령이 실행된다. 독특한 놈인데, 이벤트 핸들러와 같은 느낌으로 코딩을 하고자 할 때 응용 가능하다고 한다.
  => 하지만 잘 이해 안 된다. 스킵.
  => http://www.tutorialspoint.com/unix/unix-signals-traps.htm

15. 아파치 모듈 프로그래밍 관련
 - 모듈 개발 기본 매뉴얼: http://httpd.apache.org/docs/current/developer/modguide.html#basics
  => 다른 튜토리얼: http://threebit.net/tutorials/apache2_modules/tut1/tutorial1.html -> apxs로 함꼐 따라가면 쉽게 모듈을 만든다.
  => 리퀘스트를 다루는 구조체 request_rec 문서: http://ci.apache.org/projects/httpd/trunk/doxygen/structrequest__rec.html#a6b43edc6a8583d08944a736233838c24
  => 중요 필드: pool(리퀘스트가 사용하는 메모리 풀), args(get 파라미터의 풀 스트링), header_only(정상적인 로드를 가늠하는 변수인 거 같다), content_type(text/html, text/xml 등 문서의 속성을 결정한다. 코카스 모듈에서는 ccs_Header() 에서 이를 처리하게 된다)
 - httpd.conf 설정 정보: https://access.redhat.com/documentation/en-US/Red_Hat_Enterprise_Linux/3/html/Reference_Guide/s1-apache-config.html
 - apxs: apache extension 도구. 아파치 모듈 컴파일 및 설치 전용 도구. 예제를 따라 만들면 빌드에 드는 수고가 좀 단축되더라.
  => 사용법: http://httpd.apache.org/docs/2.4/programs/apxs.html
  => 오토서브에서 코카스 모듈을 만들 때는 사용하지 않고 있다
  => 아파치 모듈을 쉽게 만들도록 프레임을 미리 짜둔 스켈레톤 코드를 생성할 수 있다.
 - dlopen(): 실행 가능한 오브젝트 파일(주로 DSO, 동적라이브러리)을 프로그래밍 코드 내에서 실행시키는 함수.
  => http://pubs.opengroup.org/onlinepubs/009695399/functions/dlopen.html
 - 아파치 빌드 및 설치 setp by step
  => https://rajesh9333.wordpress.com/2013/07/22/apache-source-code-installation-on-centos-redhat/
  => 주요 이슈: 아파치만 빌드해서 깔면 모듈 프로그래밍을 할 수 없다. 이것저것 붙여줘야 하는 게 많음
   i) ./configure 이슈, --prefix: 설치 경로 수동 지정. 사내 시스템은 root 없이 일하는 것을 전제로. 즉 시스템 폴더나 /usr/bin 같은 기본 프로그램 폴더에 접근 못한다.
   ii) apr, apr-util: "WARNING: APR version 1.4.0 or later is required, found 1.3.9" 문구의 해결책. apr, apr-util 버젼이 아파치랑 안 맞는다. 함께 최신을 설치해줘야 하며, 나중에 모듈 프로그래밍하면서 관련 함수를 쓴다면 make 도중에 라이브러리 폴더를 꼭 설치 폴더로 지정해줘야 한다.
   iii) pcre 이슈: "checking for pcre-config… false. configure: error: pcre-config for libpcre not found." 이것도 설치 이슈. 별도 설치해준다. http://pcre.org/
   iv) ./configure, --with-apr, --with-apr-util, --with-pcre: 위 설치물들을 아파치 설치할 떄 configure에서 경로 포함시켜주는 작업.
   v) ./configure, --enable-mods-shared=all: 역시 설치 설정 관련. 동적라이브러리 사용 여부를 결정하는 것이므로 넣어줘야한다.
  => 기타 참고 문서
   i) http://ci.apache.org/projects/httpd/trunk/doxygen/group__APACHE__CORE__PROTO.html -> ap_printf() 등 ap_ 관련 함수 정리
   ii) http://ci.apache.org/projects/httpd/trunk/doxygen/group__apr__tables.html -> apr_table, apr_array 등 get 파라미터 자료를 저장하기 위한 저장소로 잘 쓰이는 구조체와 관련 멤버 함수
   iii) http://apr.apache.org/docs/apr/2.0/group__apr__strings.html -> apr_ 관련 함수 중 문자열을 처리하는 함수 집합
   iv) http://apr.apache.org/docs/apr/2.0/group__apr__pools.html -> apr_pool 관련 함수 집합 (request_rec -> pool 이 있어서 이를 다룰 때 쓴다)

16. error: template with C linkage
 - https://www.gidforums.com/t-9853.html
 - <map>, <vector> 헤더는 extern C 내부에 배치시키면 문제를 일으킨다. 헤더 배치 주의할 것

17. C문법 새로 안 것 몇가지
 - 지정자(specifier): 자료형 선언을 할 때 앞에 부티는 키워드로 기억 부류를 비롯하여 상수 지정, 최적화 금지 등 여러 성질 부여 가능
  => 종류: auto(default), extern, static, register, volatile 등
  => auto: 지역변수(자동변수). 생략 가능. 함수 내부 사용. 함수 호출 시 자동 생성, 함수 종료 시 자동 파괴
  => extern: '변수가 외부 어딘가에 구현되어 있다'. 함수 내 외부변수는 이 변수가 함수 바깥 어딘가에 있음을 알림(따라서 선언 순서에 관계 없이 외부 변수 참조 가능. 그러나 선언부를 모아 쓰는 C코딩 특성상 잘 볼일이 없다.). 가장 좋은 용도는 전역 변수가 다른 외부 모듈(프로그램, 오브젝트 파일)에 존재하는 경우에 이를 참조하려고 하는 경우. 함수 내에서 써도 되고 밖에서 써도 됨. 실무적 예는 여러 c코드가 하나의 헤더 파일을 사용하고 헤더 파일 안에 extern 변수, 함수를 몰아서 선언 정리하여 서로 다른 모듈 간의 내용을 참조하게 하는 것
  => static: 정적 변수 메모리 영역에 저장되는 지역 변수. 함수 내 선언의 경우는 함수 스코프 안, 바깥 선언의 경우는 모듈(파일) 안으로 영역 제한. 다른 모듈에서 extern 선언해서 호출 시도해도 호출되지 않는다. 데이터 메모리에 저장되므로 프로그램 시작~종료까지 살아있다. 동립적으로 동작하여 메모리 유지가 필요한 값을 가지는 함수, 외부에 노출되지 않는 데이터를 갖는 모듈에 사용 -> 재상용성 증가(바깥 모듈과 이름이 겹치는 등의 문제가 생기지 않는다)
  => http://soen.kr/lecture/ccpp/cpp1/7-1-3.png, http://soen.kr/lecture/ccpp/cpp1/7-2-1.htm

18. 콜백
 - https://ko.wikipedia.org/wiki/%EC%BD%9C%EB%B0%B1, http://lapislazull.tistory.com/79, http://msbang.co.kr/80188333982
 - 아직 콜백의 일반적인 코드 형태와 개념 설명만 알고, 실행만 시켜봤을 뿐 진짜 100% 피부로 와닿지는 않는다.
 - 중요한 건 제어권의 위치. 부르는게 아니라 불려진다
 - C나 javascript나 예제를 보면 어떤 함수의 파라미터로 들어있어 그 안에서 호출된다
 - 이벤트 핸들러의 형식으로 대기하고 있다가 OS의 호출에 의해 실행되는 식

19. tmux 2.1v 변경점
 - 2.0까지의 내용에서 변동사항이 있으니 참고해야 한다
 - mouse-mode on -> mouse on 으로 변경 
 - mouse-resize-pane, mouse-select-pane, mouse-select-window 삭제 및 mouse on으로 그냥 통합
 - mouse 관련 변화 로그: https://github.com/tmux/tmux/commit/bf635e7741f7b881f67ec7e4a5caa02f7ff3d786

 20. sed, awk
 - sed, awk: 둘다 line by line, streaming 방식으로 입력을 처리하여 출력하는 프로그램이다
  => 둘의 차이점: http://stackoverflow.com/questions/1632113/what-is-the-difference-between-sed-and-awk
 - sed: 싱글 라인으로 패턴이 있는 문서를 정규식 조작할 때 적합
 - awk: 더 복잡한 작업, 토큰으로 잘릴 수 있는 컬럼 형 데이터를 조작할 때, 멀티 라인 코딩할 때 적합
 - sed regex 문을 2개 이상 넣는 법: 구분자 세미콜론으로 이어붙임 (ex: sed -e 's/111/112/g;s/222/223/g' file)
  => sed도 결국 multi line coding 이 가능하단 소리
 - regex 내부에서 ascii 코드를 사용하는 방법 : \d00 (유니코드는 \x00인 듯)
  => ex: s/\d65/found!/g
  => http://stackoverflow.com/questions/3337936/remove-non-ascii-characters-from-csv
 - awk 명령문 중에 셸 커맨드를 실행하는 방법: system(), command | getline
  => system() ex: awk '{ system("date +%D") }'
  => http://unix.stackexchange.com/questions/72935/using-bash-shell-function-inside-awk
  => pipeline getline ex: echo | awk '{"date"|getline;print}' -> Thu Aug  9 11:41:28 METDST 2007
  => http://www.unix.com/shell-programming-and-scripting/41387-running-command-inside-awk.html
 - awk 내부에서 사용할 변수 미리 설정하기
  => BEGIN {} 사용하기 : awk 'BEGIN { test="'" } { ..actual code.. }'
  => -v 파라미터 사용하기 : awk -v test="'" '{..actual code..}'
  => 특히 몇가지 탈출문자를 써야 할 때 유용하다. 예를 들어 single quote(')는 이렇게 변수 치환해서 부르는 방법 외에는 awk 코드 안에서 출력시킬 방법이 없다. 
 - awk 내부에서 사용할 수 있는 함수
  => awk 명령어는 multi line 으로 C스타일 코드와 regex를 지원한다.
  => printf(), sprintf(), substr(), sort() 등등을 지원한다.
  => 자료형을 바꾸는 함수도 존재: int(variable)
  => 자세한 건: https://www.gnu.org/software/gawk/manual/html_node/String-Functions.html
 - awk redirection
  => awk 내부에서 리디렉션 된다. ex) print $1 > "data1"
  => https://www.gnu.org/software/gawk/manual/html_node/Redirection.html
 - awk 예약 변수
  => FILENAME: input filename.
  => FS: input field seperator. 입력 필드 구분자. default == whitespace. 단어 하나 또는 regex 지정 가능
  => OFS: output field separator. 필드 구분자. 출력문은 이것으로 출력된다. default == single space
  => FNR: file number of records. 입력 파일 하나 당 전체 줄 수. (NR과 차이: 여러 입력 파일을 넣었을 때 NR == 전체줄 수, FNR == 한 파일 줄 수)
  => NR: number of records. 현재까지 읽힌 전체 줄 수
  => NF: number of fields. 현재 레코드(줄)에서 필드(컬럼) 개수.
  => RS: record separator. 줄 구분자. default == newline
  => ORS: output record separator. 출력 줄 구분자. 출력문은 이것으로 출력된다. default == newline
 - awk 필드 접근
  => $1: 첫번째 필드
  => $0: 필드 전체 == 한 줄 전체
  => $NF: 마지막 필드
  => $(3-1): 두번째 필드. 즉 연산 가능
 - awk 연산
  => x^y, x**y: x의 y승.
  => -x: 음수
  => +x: 단항 양수(unary plus). 구체적으로 뭔말인지는 모르겠다.
  => x*y, x/y: 곱셈, 나눗셈
  => x+y, x-y: 덧셈, 뺄셈
  => x%y: 나머지
  => 주의사항: awk 내부의 수는 모두 실수 연산된다. 정수만으로 이용할 수 없음. 3/4 == 0 을 유도할 수 없다. 이 때 int(3/4)를 사용할 수 있다.
 - awk 에서 사용 가능한 연산자: c와 거의 같고 몇가지 추가되어 있음
  => http://www.staff.science.uu.nl/~oostr102/docs/nawk/nawk_117.html
 - awk 안에서 셸 명령어 사용하기: system(), command | getline
  => ex: awk '{ system("date +%D") }'
 - awk로 일부 줄만 출력하기
  => awk 'NR>=5&&NR<=9' test2, awk 'NR==5||NR==9' test2
  => http://www.unix.com/shell-programming-and-scripting/41734-how-print-specific-lines-awk.html
 - sed, awk 몇가지 심플 예제: http://egloos.zum.com/slog2/v/3689816, http://www.thegeekstuff.com/2010/01/awk-introduction-tutorial-7-awk-print-examples/
 - awk 좀 더 깊은 예제 문서: http://www.ibm.com/developerworks/library/l-awk1/ -> 2, 3까지 있다.
 - 에러메시지, BEGIN blocks must have an action part: 중괄호를 c스타일로 한줄 개행하고 넣으면 발생하는 문제. "BEGIN {" 과 같이 바로 다음에 괄호하라.
 - awk 에서 특정 문자열만 선택하기(regex?)
  => ls -al | awk 'BEGIN{} /irteam/ {print $0}' -> 이런 표현이 가능! irteam이 들어있는 줄만 처리한다. BEGIN{} 없어도 됨
  => 출처 이설 선임님. 찾아볼 것.
 - awk 에서 if 사용
  => http://www.thegeekstuff.com/2010/02/awk-conditional-statements/
 - awk 에서 array iteration
  => awk '{my_dict[$1] = $2} END { for (key in my_dict) { print my_dict[key] } }' zen -> 이런 식으로 for in iteration 가능
  => 그런데 순서가 무작위다. 왜인지 모름. 찾아볼 것.
  => http://unix.stackexchange.com/questions/183279/how-to-view-all-the-content-in-an-awk-array

21. shell 프로그래밍
 - #!: 샾뱅. 스크립트 실행기 지정 (ex: #!/bin/sh => 이 스크립트가 sh 스크립트임을 의미). 스크립트 첫번째 줄에 작성
 - 내장 셸 변수 (Built-in shell variables)
  - 예문을 들어 설명: run.sh arg1 arg2
  - $#: 셸 프로그램에서 넘겨받은 커맨드라인 인자들의 개수 (2)
   - $1: 첫번째 인자 (arg1)
   - $2: 두번쨰 인자 (arg2)
  - $?: 마지막 실행 명령어의 종료(exit) 코드를 반환 (정상이면 0)
  - $0: 입력 커맨드 문자의 맨 첫번쨰 단어 -> 셸 프로그램의 이름 (run.sh)
  - $*: 커맨드라인에 입력했던 모든 인자들, 문자열 (arg1 arg2)
  - $@: 커맨드라인에 입력했던 모든 인자들, 배열. ({"arg1", "arg2"})
  => http://linuxsig.org/files/bash_scripting.html
 - for loop: for i in 1 2 3 4 5  ==  for i in {1..5}  ==  for((i=0; i<5; i++))
  => for 이후 반복 구문은 do, done 으로 묶는다. (ex: for i in {1..5}; do echo $i; done)
  => http://blog.naver.com/vjamp/220388193622, http://www.freeos.com/guides/lsst/ch03sec06.html
 - while loop: while [ condition ] do code done
  => http://www.cyberciti.biz/faq/bash-while-loop/
 - 변수를 이용한 정수 수식 계산: $(( )), 소수점이 있는 실수는 계산 불가
  => ex: TEST=134; echo $((TEST-136))
  => http://unix.stackexchange.com/questions/50215/calculate-variable-and-output-it-to-another-variable
 - if: if[]; then 조건식 elif[]; then 조건식 else 조건식 fi
  => if 비교연산자: http://www.dreamsyssoft.com/unix-shell-scripting/ifelse-tutorial.php
  => if 비교연산자2(bash): http://tldp.org/LDP/Bash-Beginners-Guide/html/sect_07_01.html
  => not(!)의 활용예: ex) if [ ! -f $FILE ];
 - 셸 스크립트 함수 특이점: return 0 가 true, 1이 false다!
  => http://stackoverflow.com/questions/5431909/bash-functions-return-boolean-to-be-used-in-if
  => 셸 스크립트 함수 작성 기초: http://www.cyberciti.biz/faq/bash-shell-script-function-examples/
  => 함수의 지역 변수 전역 변수: http://www.thegeekstuff.com/2010/05/bash-variables/
  => 단, 함수 내에서 전역 변수 바꾸기는 한 줄에서 함수를 단독 실행해야만 효과가 있다. 이유는 여러 파이프나 if 문 내의 실행은 서로 다른 shell에서 실행되기 때문.
      ex) func1 안에서 전역변수 GLOBAL="true" 가 있다면
      func1 - (o)
      if ( func1 ) - (x)
      func1 | grep something - (x)
 - 알아야 할 기본 명령어: if, exit, for, while, until, case, break, continue
 - > /dev/null: stdout 버리는 곳. 이거좀 까먹지 말자
 - 2>&1: 2채널(stderr)을 1채널(stdout)로 리디렉션한다. 1 앞의 &은 1이 파일이름이 아니라 파일 설명자(file descriptor)임을 말한다. 이걸로 에러와 아웃이 모두 나온다. 까먹지 말자
   => http://stackoverflow.com/questions/818255/in-the-shell-what-does-21-mean
 - &: 백그라운드 실행
 - bash shell 각종 특수문자 가이드: http://tldp.org/LDP/abs/html/special-chars.html
 - 체인 연산자(&, ;, &&, {}, (), ...) 관련 레퍼런스: http://www.tecmint.com/chaining-operators-in-linux-with-practical-examples/
 - command substitution: 셸 명령 결과를 변수 할당
  => sh 지원하는 것으로 보임
  => 문법: ``, $()
  => ex) RESULT=`ls -al`
  => ex) RESULT=$(ls -al)
 - process substitution: 프로세스 결과를 다른 프로세스로 전달. 명령 결과 -> 다른 명령 입력. FIFO 방식, 파일로 만들어 전달. 저장소는 /dev/fd/.
  => bash만 지원하는 것으로 보임. sh는 이것을 직접 구현해야 한다.
  => >(), <(). 화살표 방향으로 넣는 것.
  => ex) cat <(ls -al) == ls -al | cat
  => ex) command > >(tee stdout.log) 2> >(tee stderr.log >&2)
    : 커맨드를 실행해서 stdout을 출력과 동시에 stdout.log로, stderr는 출려과 동시에 stderr.log로 저장한다.
  => ex) diff <(ls -l) <(ls -al)
    : ls -l, ls -al을 만들어 두 입력을 diff 비교한다.
  => ex) tar cf >(bzip2 -c > file.tar.bz2) directory
    : 
  => http://stackoverflow.com/questions/692000/how-do-i-write-stderr-to-a-file-while-using-tee-with-a-pipe

22. elastic search
 - http://helloworld.naver.com/helloworld/273788: 전반적인 기본 튜토리얼 및 기초 운영 팁
 - http://hyeonjae.ghost.io/elasticsearch-1-seolci-mic-saegin/: 나우팍의 정리
 - 플러그인 개념
  => elasticsearch/bin/plugin 프로그램이 관장 (이 명령어에 -install, -remove, -list로 플러그인 관리)
  => 주요 플러그인: head, bigdesk, jetty, thrift, arrayformat
  => head: ./plugin -install mobz/elasticsearch-head (http://mobz.github.io/elasticsearch-head)
  => bigdesk: ./plugin -install lukas-vlcek/bigdesk
  => jetty, thrift: 분석기, netty->jetty 플러그인인데 자세한건 알아봐라
  => arrayformat: 출력물을 메타데이터 전부 걷어내고 순수 데이터만 json 배열로 뽑아준다. ./plugin -install arrayformat -url http://xbib.org/repository/org/xbib/elasticsearch/plugin/elasticsearch-arrayformat/1.4.0.0/elasticsearch-arrayformat-1.4.0.0-plugin.zip (https://github.com/jprante/elasticsearch-arrayformat) 메타 데이터 정보를 전체 또는 일부 없애고 출력하는 이슈는 이미 존재했다. es 깃헙 이슈에서 볼 수 있는데 공식 입장은 딱히 지원할 생각 없는 듯. (https://github.com/elastic/elasticsearch/issues/2149)
 - api 개념: es의 api는 url에 언더바로 시작하는 명령어를 입력하여 보통 하용하는 모양새
  => ex: _search, _bulk, _update, ...
 - 검색 방식: 크게 2가지. _search 플러그인으로 url 직접 간단 검색하기, JSON request body로 query DSL 사용하여 세부 검색하기
  => _search api: url~~~/_search?q="검색어"
  => requset body: url~~~/_search -d '{ JSON body }'
  => query DSL 레퍼런스: https://www.elastic.co/guide/en/elasticsearch/reference/current/query-dsl.html
  => 유용한 query DSL: bool, query string, multi_match
 - 페이징 개념(pagination)
  => 한 쿼리에 너무 많은 검색 결과를 노출시켜주는 것은 es cluster에 대단한 부하를 주는 것 같다 (http://stackoverflow.com/questions/14396582/setting-elastic-search-limit-to-unlimited)
  => 페이징은 기본 개념이며, 디폴트로 from:0, size:10 으로 지정되어 있다 (https://www.elastic.co/guide/en/elasticsearch/reference/1.6/search-request-from-size.html)
  => 이것을 바꾸지 않기 때문에 리퀘스트 바디 검색으로 결과가 아무리 많아도 자꾸 10개만 나오는 것
 - bulk api: 한 번에 여러개의 동작을 시킬 떄 사용하는 api로 주로 문서 인입할 때 유용하다(index, create 등)
  => 뚜렷한 제한은 없지만 uri  1회 호출당 1~5000 개가 적당, 만 건 이상을 넘어가면 오류가 나기도 한다(책 인용: 시작하세요! 엘라스틱서치 89p.)
 - 파일 입력: -XPOST url~~~/ --data-binary @파일명
  => bulk랑 연동하여 미리 꾸며진 json 문서들을 한번에 올린다면 이것이 좋은 방법
 - id 로 정렬하기
  => 문서 안에 0이나 1로 시작하는 유니크 키나 순차번호가 들어있지 않다면 수를 세는 것은 꽤나 불편
  => 검색 결과 정보의 메타데이터 필드를 보면 "_id" 로 노출되는 값이 있는데 이것이 도움이 될 수 있다
  => 그러나 리퀘스트 바디에서 sort 파라미터를 쓸 수 있음에도, "sort" : "_id" 하면 원하는 동작이 되지 않는다
  => 정답은 "sort" : "_uid" 이다. 이유는 자세히 안 읽어봄 (https://github.com/elastic/elasticsearch/issues/1756)
  => 그러나 이거로 정렬해도 아직 문제가 있다. 숫자가 문자열로 인식되기 때문에 정렬 결과는 이런 식이다 (37,38,39,4,40,41,42,...)
  => 때문에 나의 경우 숫자만 정렬해서 필요하다면 정렬 없이 uid를 찍고 redirect 로 sort 하는 방법을 씀 (curl ~~~~ | sort -n)

23. linux shell programming, 괜찮은 코드 스니펫
 -  chr() {
        [ "$1" -lt 256 ] || return 1
        printf "\\$(printf '%03o' "$1")"
    }

    ord() {
        LC_CTYPE=C printf '%d' "'$1"
    }
 - usage:
    chr 65
    A

    ord A
    65

24. \n vs. \r
 - \n: 일반적으로 엔터키(newline)
 - \r: 일반적으로 캐리지 리턴(CR, carriage return)
 - linux vi에서:
  => 검색할때, \n == newline, \r == CR == Ctrl-M == ^M
  => 치환할때, \n == null byte!!! (0x00), \r == newline 헐 졸라쇼크..
  => http://vim.wikia.com/wiki/Search_and_replace
  => 왜 이런거지?? : http://stackoverflow.com/questions/71417/why-is-r-a-newline-for-vim

25. redirect(|) 도중 이상한 내용이 추가되어 나올 때(total received xferd average speed time time time current)
 - 주로 curl 이후 내용을 redirect 할 때 발생한다
 - 원치 않은 progress message가 등장한다
 - curl 옵션 -s (--silent) 를 이용해 이 출력을 없앨 수 있다

26. 파일 비교 명령어
 - http://blog.naver.com/rrrsh/220339956376
 - diff 말고 comm 이 있다는 것을 알았다. 되게 유용한 듯.

27. 오토서브 사전 버젼 바꾸는 법
 - 관리 -> 사전 -> 편집 버튼 클릭으로 사전 버젼을 선택할 수 있다
 - 버젼이 없을 경우 집어넣는 법
  => 이 부분은 오토서브가 autosetup을 해서 새 환경 구성 시 원격 저장소에서 내용을 가지고 오면서 채워진다
  => 따라서 원격 저장소의 linguist2 사전 폴더를 구성해놓고 새로 autosetup 하면 추가하고 싶은 버젼을 볼 수 있다
  => repos.search.nhnent.com, sss 등 원격저장소의 사전폴더(/naver/pkgs/linguist2-share/) 내부를 적절히 구성하고, autosetup 한 후 사전 편집 화면 변화를 확인하라

28. 서버의 성능측정
 - 참고 사이트: https://www.linux.co.kr/home2/board/bbs/board.php?bo_table=lecture&wr_id=961&sca=2
 - 방법 1: apache ab
  => 장점: 아파치만 깔려있으면 기본 내장, 무료, 다중 실행, 복수 실행, 테스트 시간 길이 설정 등이 가능
  => 알 수 있는 정보:
| Server Software | 아파치버전을 표시 |
|Server Hostname |특정사이트의 이름(도메인명) |
|Server Port |웹서비스 사용포트번호 |
|Document Path |초기 문서가 준재하는 웹문서 root위치 |
|Time take for tests |응답시간(매우 중요한 결과 값임) |
|Document Length |초기문서(대부분 index.html, index.htm)의 용량크기 |
|Complete requests |요구에 응답완료한 세션수 |
|Failed requests |요구에 응답실패한 세션수 |
|Broken pipe errors |실패한 에러수 |
|Total transferred |총 전송바이트수 |
|HTTP transferred |총 전송한 HTML바이트수 |
|Requests per second |초당응답요구수 |
|Time per request |요구에 응답한 시간(단위 micro second, 중요한 결과값) |
|Time per request |요구에 응답한 시간 |
|Transfer rate |초당전송가능한 용량 |
 - 방법 2: httperf
  => 다운로드: http://www.hpl.hp.com/research/linux/httperf
  => 설치: ./configure ; make; make install
  => 장점: 서버/포트/접속수/초당접속수/타임아웃/think타임아웃/hog(가능한 모든 포트 사용) 설정 가능. 이외 파악 중
 - 방법 3: flood
  => 다운로드: svn co http://svn.apache.org/repos/asf/httpd/test/trunk/flood
  => 장점: URL 과 POST data 를 여러 서버들에 테스트 가능
  => 단점: xml 설정파일 필요, apr, apr-util 추가 설치 필요. (svn co http://svn.apache.org/repos/asf/apr/apr/trunk apr; svn co http://svn.apache.org/repos/asf/apr/apr-util/trunk apr-util)
  => 참고: http://httpd.apache.org/test/flood/faq.html

29. tmux 몇가지 이슈 및 해결 정리
 - 안에서 vim이 멈췄다면 의심해볼 문제
  => ctrl+s 를 무심코 눌렀을 수 있다. 터미널 flow control을 끄는 단축키. ctrl+q 누르면 돌아온다.
  => http://superuser.com/questions/553330/vim-freezes-inside-tmux
 - vim에서 삽입모드가 너무 느리다
  => tmux man 페이지에 관련 내용이 있는 것 같다. 다음의 코드를 .tmux.conf 에 삽입.
  => set -sg escape-time 0
  => http://superuser.com/questions/252214/slight-delay-when-switching-modes-in-vim-using-tmux-or-screen

30. 리눅스(linux) 한글의 정렬
 - 왠지 그냥은 안된다
 - LC_ALL=C sort < 정렬하고자 하는 파일이나 입력
 - 위는 된다. 이유는 모른다. 찾아볼 것 => man sort에 명시되어있다. sort 대상 파일의 인코딩과 shell locale을 일치시켜야 한다.
 - euckr에는 euckr, utf8에는 utf8 등으로 정확히 맞추는게 best지만 C는 범용적으로 다 된다. 아마도 C는 바이트코드가 아닌가 생각하고 있다.
 - http://unix.stackexchange.com/questions/67841/sort-lines-by-unicode-value
 - http://codezip.tistory.com/470

31. linguist2/bin 에 들어있는 네이버 개발, 유용한 툴
 - hanaterm: 하나텀을 이용해 형태소분석을 한다.
  => 인풋, 아웃풋을 모두 파일 지정해야 하고, --help에서 요구하는 필요 옵션을 모두 기입해야 동작한다.
  =>  ex: hanaterm -f temp -F temp_result -d /naver/search-env/package/linguist2-5.0-20150204-ne-arch-x86_64/share -m sgmt +korea +alphanum
  => temp를 열어 결과 분석을 temp_result로 저장한다. 사전 경로는 -d, 사용 method는 sgmt, 추가된 룰은 +korea, +alphanum 이다.
 - bugyconv: iconv와 하는 일은 똑같다. 텍스트 문서 인코딩을 바꿔준다.
  => iconv보다 유리한 점은 euckr->utf8 변환이나 어떤 변환 도중 오류를 일으키는 문자가 나왔을 때 프로그램이 죽지 않고 처리를 해준다는 것
  => 네이버에서 이거 개발하신 개발자님께서 아들의 이름을 따서 프로그램 이름을 지었다는 후문.. 다른 프로그램도 다 bugy로 시작한다고..

32. vi 의 좋은 기능
 - .: 직전 기능 반복 실행
  => ex: 3dd -> 3줄 지움 -> . -> . -> . -> ... (3줄 계속 지움)
  => 복붙도 이게 훨씬 편하다
 - 헥사 뷰어
  => :%!xxd -> 헥사 모드 전환.
  => :%!xxd -r -> 원래대로.
  => http://mwultong.blogspot.com/2007/08/vim-vi-hex-viewer-hex-editor-xxd.html

33. fork(), execl(), wait() : 멀티스레드 프로그래밍 전에 알아야 할 기초, 멀티프로세스 프로그래밍
 - exec: c코드 내에서 새로운 외부프로그램을 실행하는 함수
  => 관련 함수셋들이 많은데 execl, execvp 등이 있다
  => 특이점은 실행 직후 parent process는 죽는다는 것. 이후의 코드는 실행되지 않는다
  => pid = 그대로 -> 따라서 기존 프로세스의 '대체' 상황이라고 생각하면 된다
 - 실전적으로 fork는 멀티프로세스 프로그래밍을 의미한다
 - fork는 리눅스에서 현재 실행 중인 프로세스를 그대로 복사한 child process를 만들어 실행시킨다
  => 실행시점은 fork()라인 직후부터.
  => pid = 새로운 숫자
  => ppid = 부모 pid -> 이것으로 코드 내에서 분기를 써서 지금이 부모 프로세스인지 자식 프로세스인지 판단한다. 이게 0이면 부모 프로세스, 음수면 에러.
  => 복제이므로 서로 독립적인 메모리 공간을 갖는다
  => 그렇다고 비효율적인 완전 생 카피는 아니고 heap 영역 외에 반복적인 부분에서 공유하는 영역이 존재
  => 동작은 멀티스레딩과 결국 비슷한 개념
 - 멀티스레딩 = Light Weight Processes (LWPs)
  => 저 컨텍스트 스위칭과 복제로 인한 오버헤드를 줄이고자 하는 것이 더 근본적인 컨셉
  => 동작 목표는 동일하다
 - execl, fork, vfork: http://sonseungha.tistory.com/291
 - fork vs. thread: http://www.geekride.com/fork-forking-vs-threading-thread-linux-kernel/
 - wait 사용법 관련 문서: http://www.joinc.co.kr/modules/moniwiki/wiki.php/man/2/wait

34. fabric
 - 파이썬 라이브러리
 - subprocess, popen 등보다 훨씬 좋은 외부프로그램 실행 관련 함수들을 제공
 - http://www.fabfile.org/
 - 트위터에서 배포하는 앱개발 관련 fabric이라는 놈도 우연히 나왔는데 이게 뭔진 모르겠다 https://get.fabric.io/

35. x-forwarded-for
 - 평소 서버-클라이언트 환경이라면 사용자 IP를 알아내고 싶을 때 HTTPServletRequest를 까보면 된다 (자바로 설명)
  => ex) request.getRemoteAddr()
 - 그런데 서비스 구성 중간에 프록시, L4 스위치, 로드밸런서가 끼어있다면 리모트 IP를 단순히 까봤자 당연히 로드밸런서의 IP가 나온다.
 - 이는 원하는 결과가 아니다.
 - 이 때문에 실제 클라이언트 IP를 보여주는 헤더 기술이 사용되었는데 그것이 X-Forwarded-For 헤더.
 - 비표준이다. 하지만 가장 널리 사용됨.
 - 이외에는 Proxy-Client-IP, WL-Proxy-Client-IP, HTTP_CLIENT_IP, HTTP_X_FORWARDED_FOR 등이 알려져 있는 듯 하다.
 - X-Forwarded-For 헤더 내부 구성
  => X-Forwarded-For: client, proxy1, proxy2
  => 따라서 첫번째 IP를 가져오면 사용자 IP를 알 수 있다.
 - WAS, 프로그래밍 레벨에서 알아내는 소스 코드
  =>
    String ip = request.getHeader("X-Forwarded-For");
    if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { 
      ip = request.getHeader("Proxy-Client-IP"); 
    } 
    if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { 
      ip = request.getHeader("WL-Proxy-Client-IP"); 
    } 
    if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { 
      ip = request.getHeader("HTTP_CLIENT_IP"); 
    } 
    if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { 
      ip = request.getHeader("HTTP_X_FORWARDED_FOR"); 
    } 
    if (ip == null || ip.length() == 0 || "unknown".equalsIgnoreCase(ip)) { 
      ip = request.getRemoteAddr(); 
    }
 - Apache web server에서 이를 처리하는 방식
  => LogFormat 표시 조작: LogFormat "%{X-Forwarded-For}i %l %u %t \"%r\" %>s %b" common
  => 
 - http://lesstif.com/pages/viewpage.action?pageId=20775886

 - 스프링 시큐리티 expression handler 작성법: http://kwonnam.pe.kr/wiki/springframework/security#global-method-security에_핸들러_지정
 - SpEL: http://docs.spring.io/spring-framework/docs/current/spring-framework-reference/html/expressions.html
 - SecurityExpressionRoot에 구현된 Common Built-In Expressions: http://docs.spring.io/spring-security/site/docs/3.2.8.RELEASE/reference/htmlsingle/#el-common-built-in
 -


36. 유용한 리눅스 셸 스크립트
 - DIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" && pwd )"
  => 이 1라인 코드는 스크립트가 실행된 디렉토리 경로를 어디서 스크립트를 호출하든 상관없이 잘 보여줄 것
 - 우리는 도로명주소 hqr 서버 컬렉션 덤프 프로그램 스크립트에서 이 코드가 사용되었음
 - http://stackoverflow.com/questions/59895/can-a-bash-script-tell-what-directory-its-stored-in

37. 리눅스 파일 계층 구조, /bin vs. /usr/bin vs. /usr/local/bin vs. /sbin
 - /bin: 기본 프로그램. 전체 사용자용. (ex: cat, chmod, chown, cp, date, echo, kill, ln, ls, mkdir, more, mount, mv, ps, pwd, rm, sh, su, vi ..)
 - /sbin: Standalone Binary File Directory. 시스템 운영 프로그램. (ex: halt, reboot, fdisk, mkfs ..)
 - /usr: 가장 많은 용량을 차지하는 부분. 대부분의 프로그램 설치 디렉토리
  - /usr/bin: distribution-managed normal user programs. 패키지 프로그램으로 관리되는 사용자 프로그램. (ex: gcc, perl, ..)
  - /usr/local: 새로운 프로그램 설치 장소. make install 기본 프리픽스 위치.
  - /usr/local/bin: 패키지 관리 프로그램으로 관리되지 않는 설치 프로그램들 (컴파일하여 사용하는 프로그램들)
 - 이전에는 /, /usr, /usr/local을 따로 파티션 나누어 사용했었는데 현재도 서버 운영을 한다면 가치가 있는 설정이다.
  - 오류 복구가 용이하고, 디스크 단편화 문제를 줄일 수 있다.
  - 그러나 용량 운영 융통성은 떨어져서 현재는 잘 하지 않는 편
  => https://kldp.org/node/42376
 - https://en.wikipedia.org/wiki/Filesystem_Hierarchy_Standard
 - http://coffeenix.net/doc/kuls/file_system-4.html
 - http://noon.tistory.com/936
 - http://unix.stackexchange.com/questions/8656/usr-bin-vs-usr-local-bin-on-linux

38. rpm
 - 설치: rpm -ivh 패키지명
 - 확인: rpm -qa | grep 패키지명
 - 제거: rpm -ev 패키지명
 - 업글: rpm - Uvh 패키지명
 - 파일이 속한 패키지 찾기: rpm -qf 파일
 - 패키지 정보: rpm -qi 패키지명, rpm -qip 파일명.rpm
 - 패키지 내부 파일 목록: rpm -ql 패키지명, rpm -qlp 파일명.rpm -> 이걸로 패키지 설치된 라이브러리의 파일 경로를 찾을 수도 있다
 - 내부 문서파일 확인: rpm -qd 패키지명, rpm -qdp 파일명.rpm
 - 내부 스크립트: rpm -q --scripts 패키지명, rpm -qp --scripts 파일명.rpm
 => http://zetawiki.com/wiki/%EB%A6%AC%EB%88%85%EC%8A%A4_rpm_%EC%82%AC%EC%9A%A9%EB%B2%95

39. 아파치 - 톰캣 연동
 - 간단한 서비스는 단일 톰캣으로도 서비스 가능하지만
  - 유저 레벨에서 구동한 단일 톰캣은 1024번 포트 밑으로 포트 설정을 하는게 제한됨 -> 루트 실행이 필요
  - 단일 WAS는 웹서버 - WAS 구성보다 서비스를 함에 있어 부하 분산 및 성능 제공에 불리
  - 아파치 - 톰캣 구성이 보다 보편적인 업계 서비스 서버 구성 방식
   => 따라서 아파치를 루트로 가동하고 아파치가 톰캣으로 포워딩하는 식으로 정적 페이지 - 동적 페이지 분산 처리 및 80/443(https, ssl) 포트 접근을 가능하게 함
 - 웹서버 - WAS 연동 방법
  - apache(httpd) - tomcat
   - mod_jk: 널리 사용. 별도 모듈 설치 필요. 설정이 상대적으로 살짝 복잡. 톰캣 전용 -> 채택 권장
   - mod_proxy: 아파치 기본 제공 모듈. 설정이 간편. 모든 WAS에 적용 가능. URL별 유연한 설정이 어렵고 ProxyPassMatch 사용이 필요
   - mod_proxy_ajp: 아파치 기본 제공 모듈. 설정이 간편. 모든 WAS에 적용 가능. URL별 유연한 설정이 어렵고 ProxyPassMatch 사용이 필요
  - nginx - tomcat
   - nginx: 아파치를 대체할 차세대 웹서버
 - 과정 (핵심만)
  - http://tomcat.apache.org/download-connectors.cgi -> mod_jk 모듈 다운로드, 컴파일 및 설치 (httpd, httpd-devel, gcc, gcc-c++ 필요)
  - httpd.conf -> LoadModule jk_module modules/mod_jk.so, Include 적절한경로/mod_jk.conf
  - mod_jk.conf -> <IfModule mod_jk.c> 관련 설정을 넣게 됨. workers_jk.properties, uriworkermap.properties 읽음
  - JkWorkersFile workers_jk.properties -> ajp protocol connector 설정 파일
   => 톰캣/conf/server.xml 에서 <Connector port="8009" protocol="AJP/1.3" redirectPort="8443" URIEncoding="UTF-8"/> 정보를 확인하여 작성
  - JkMountFile uriworkermap.properties -> uri 매핑 파일
 => https://www.lesstif.com/pages/viewpage.action?pageId=12943367
 => http://nomore7.tistory.com/entry/Apache-Tomcat-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0-1%EC%97%B0%EB%8F%99%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0
 => http://nomore7.tistory.com/entry/Apache-Tomcat-%EC%97%B0%EB%8F%99%ED%95%98%EA%B8%B0-2%EC%97%B0%EB%8F%99%ED%95%98%EB%8A%94-%EB%B0%A9%EB%B2%95modjk-%EC%9D%B4%EC%9A%A9

 40. C언어
  i) getopt.h, unistd.h -> getopt(), getopt_long()
   - 유닉스: unistd.h
   - 리눅스: getopt.h
   - int main(int argc, char* argv[]) 에서 받는 argv 인자를 분석하여 편리하게 사용하게 해주는 라이브러리.
   - getopt(): - 문자 옵션만 사용
   - getopt_long(): -- 문자 옵션과 같은 긴 옵션도 사용
   - http://forum.falinux.com/zbxe/index.php?mid=C_LIB&sort_index=blamed_count&order_type=asc&page=5&listStyle=gallery&document_srl=519764
   - http://blog.naver.com/cdincdin/30120565533

